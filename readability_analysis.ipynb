{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='Article.txt' mode='w' encoding='cp1251'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During this pandemic, every activity in an indoor public place involves some level of risk, but some venues are far riskier than othersвЂ”especially if theyвЂ™re small and crowded.\\n\\nWe already knew that restaurants can easily become covid hot spots, but a new paper published in Nature today quantifies just how dangerous they really are: four times riskier than the next riskiest location, which was the gym. However, there could be a simple way to reduce the danger. Caps on the number of people permitted to be inside a restaurant simultaneously could cut infections drastically, according to a new model created by the team of epidemiologists, computer scientists, and social scientists from Stanford and Northwestern universities.\\n\\nThe researchers used smartphone data to predict where people were catching the coronavirus. They used data on the movements of almost 100 million people in the 10 biggest cities in the US from March 1 to May 1, 2020, provided by SafeGraph, a company that aggregates anonymized location data from smartphone apps. They collected the movements of people between their neighborhoods and points of interest like gyms, grocery stores, restaurants, or places of worship. \\n\\nThen they used the smartphone data to predict infections on the basis of three metrics: how big the venue was, how long people stayed inside it, and how many people were likely to be infectious in the given area. Finally, they compared their modelвЂ™s predicted number of infections with the official number of infections recorded in those neighborhoods over that same period. The new model was able to accurately predict actual cases, the team said. \\n\\nBy simulating various scenarios using the model (full capacity reopening, or caps at 50%, for example), the researchers found that implementing occupancy caps of 20% of capacity would cut infection rates by 80% while minimizing the economic impact. The study found that just 10% of locations accounted for 85% of infections in Chicago in the time period examinedвЂ”likely down to so-called superspreading events. This suggests that occupancy caps could significantly cut transmission rates, while allowing businesses to stay open. Since these caps would mostly only impact visits during peak hours, restaurants would lose about 42% of customers on average. The authors emphasized that measures like mask-wearing and social distancing would also have to be part of the mix to reopen safely.\\n\\nвЂњOur work highlights that it doesnвЂ™t have to be all or nothing, and we can choose different methods for different places,вЂќ said Jure Leskovec, an associate professor of computer science at Stanford University and one of the paperвЂ™s authors, at a press conference today. вЂњOur work provides a tool for policymakers to navigate the tradeoffs.вЂќ\\n\\nThe study also shed some more light on exactly why your risk of catching, and dying from, covid-19 correlates so closely with your ethnicity and socioeconomic background. First, the model found that people in neighborhoods with fewer white people and lower average incomes do not have as much opportunity to reduce their mobility, no doubt because theyвЂ™re less likely to have jobs they can do from home. Not only that, but the places that lower-income groups visit tend to be more crowded, which increases the risk of infection. The study found that the grocery stores frequented by people with lower incomes are typically more tightly packed and shoppers tend to stay inside for longer, making these visits twice as dangerous.\\n\\nThere is an obvious drawback to occupancy caps: they reduce the amount of money businesses can pull in, potentially to the point where they become economically unviable. Working out how businesses make enough money to stay open while capping how many people can visit them, or whether the government should subsidize businesses to keep them afloat with restricted customer numbers, is the next complex and contentious issue to tackle. Over to you, economists.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = open(\"Article.txt\", \"r\")\n",
    "article_text=article.read()\n",
    "article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['involves', 'some', 'level', 'of', 'risk,', 'but', 'some', 'venues', 'are', 'far', 'riskier', 'than', 'othersвЂ”especially', 'if', 'theyвЂ™re', 'small', 'and', 'crowded.', 'We', 'already']\n"
     ]
    }
   ],
   "source": [
    "#print(article_text)\n",
    "words=article_text.split()\n",
    "print(words[10:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_symb = 3992\n"
     ]
    }
   ],
   "source": [
    "#symbols count\n",
    "n_symb = 0\n",
    "for i in article_text:\n",
    "    n_symb = n_symb + 1\n",
    "print(\"n_symb =\",n_symb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_sent = 24\n"
     ]
    }
   ],
   "source": [
    "#\"Sentences\" count\n",
    "n_sent = article_text.count('.')+article_text.count('?')+article_text.count('!')\n",
    "print(\"n_sent =\",n_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_proper = 12\n",
      "Naming index = 0.018957345971563982\n"
     ]
    }
   ],
   "source": [
    "#proper names count\n",
    "d = dict.fromkeys(string.ascii_uppercase, 0)\n",
    "n_proper = 0\n",
    "for word in words:\n",
    "    uppercase=0\n",
    "    for letter in word:\n",
    "        if letter in d:\n",
    "            uppercase = uppercase + 1\n",
    "    if (uppercase != 0):\n",
    "        #print(word)\n",
    "        n_proper = n_proper + 1\n",
    "#proper names without sentences\n",
    "n_proper = n_proper - n_sent\n",
    "print(\"n_proper =\", n_proper)\n",
    "naming_index = n_proper/len(words)\n",
    "print(\"Naming index =\", naming_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n",
      "We\n",
      "we\n",
      "all_words = 633\n",
      "Number of personal words = 2 \n",
      " Personality index = 0.022116903633491312\n"
     ]
    }
   ],
   "source": [
    "#words and sentences count\n",
    "all_words = 0\n",
    "print(len(words))\n",
    "n_personal = 0\n",
    "for word in words:\n",
    "    all_words = all_words + 1\n",
    "    if word in (\"I\",\"i\",\"our\",\"Our\",\"we\", \"We\", \"WE\",\"us\"):\n",
    "        print(word)\n",
    "        n_personal = n_personal + 1\n",
    "personality_index = n_personal/all_words*7\n",
    "print(\"all_words =\",all_words)\n",
    "print(\"Number of personal words =\",n_personal,\"\\n\",\"Personality index =\", personality_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FleschReadabilityEase(text, all_words, n_sent):\n",
    "\tif len(text) > 0:\n",
    "\t\treturn 206.835 - (1.015 * all_words/n_sent) - 84.6 * (sum(list(map(lambda x: 1 if x in [\"a\",\"i\",\"e\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"y\"] else 0,text)))/all_words)\n",
    "\n",
    "def ARI(text, all_words, n_sent, n_symb):\n",
    "    score = 0.0 \n",
    "    if len(text) > 0: \n",
    "        score = 4.71 * (n_symb / all_words ) +  0.5 * ( all_words / n_sent) - 21.43 \n",
    "        return score if score > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch Readability =  6.320299170616124\n",
      "ARI readability =  21.461007109004733\n"
     ]
    }
   ],
   "source": [
    "print(\"Flesch Readability = \", FleschReadabilityEase(article_text, all_words, n_sent))\n",
    "print(\"ARI readability = \", ARI(article_text, all_words, n_sent, n_symb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/linguistic-complexity-measures-for-text-nlp-e4bf664bd660\n",
    "# https://methods.sagepub.com/dataset/howtoguide/dictionary-based-sentiment-analysis-in-econnews-2016-python\n",
    "# readability formulas\n",
    "# article texts : https://www.technologyreview.com/2020/11/10/1011930/a-cap-on-numbers-in-restaurants-could-stop-them-becoming-covid-hotspots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observations: \n",
    "# 1) Delete punctuation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
